# ragFlow - Pr√≥ximos Passos

> **√öltima atualiza√ß√£o**: 2025-11-20
> **Branch atual**: `002-async-refactor`
> **Prioridade**: üî¥ CR√çTICO - Refatora√ß√£o Async/Await

---

## üö® PROBLEMA CR√çTICO IDENTIFICADO

### ‚ö†Ô∏è Sistema N√ÉO est√° usando Processamento Ass√≠ncrono Real

**Status Atual**: Todo o pipeline RAG est√° rodando de forma **S√çNCRONA**, bloqueando threads e limitando severamente a performance.

**Impacto na Performance**:
- Cada query processa sequencialmente (~3-7 segundos bloqueando)
- Worker n√£o pode processar m√∫ltiplas queries simultaneamente
- Chamadas √† OpenAI bloqueiam (~500ms-1s para embeddings, 2-5s para gera√ß√£o)
- Chamadas ao Qdrant bloqueiam (~200-500ms)
- **Throughput**: ~10-20 queries/minuto (deveria ser 100+)

### üéØ Objetivo da Branch 002-async-refactor

Refatorar completamente o sistema para usar **async/await verdadeiro** em Python, permitindo processamento concorrente de queries e melhor utiliza√ß√£o de recursos.

---

## üìã Plano de Refatora√ß√£o Async

### Phase 1: Atualizar Depend√™ncias (0.5h)

**T062: Adicionar bibliotecas async ao requirements.txt**

```txt
# Adicionar:
aiohttp>=3.9.0           # Cliente HTTP async
aioboto3>=12.0.0         # AWS SDK async (se necess√°rio)
asyncpg>=0.29.0          # PostgreSQL async driver
aio-pika>=9.3.0          # RabbitMQ async client
httpx>=0.25.0            # Cliente HTTP async alternativo

# Atualizar vers√µes:
openai>=1.10.0           # J√° suporta AsyncOpenAI
qdrant-client>=1.7.0     # J√° suporta AsyncQdrantClient
sqlalchemy[asyncio]>=2.0.25  # SQLAlchemy async
```

**Arquivos afetados:**
- `requirements.txt`

---

### Phase 2: Refatorar Services para Async (2-3h)

**T063: Refatorar EmbeddingService para async**

**Arquivo**: `src/services/embedding_service.py`

**Mudan√ßas**:
```python
from openai import AsyncOpenAI  # ‚Üê Mudar de OpenAI para AsyncOpenAI

class EmbeddingService:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.openai_api_key)  # ‚Üê Async

    async def generate_embedding(self, text: str) -> List[float]:  # ‚Üê async def
        # ...
        response = await self.client.embeddings.create(  # ‚Üê await
            model=self.model,
            input=text,
        )
        # ...

    async def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:  # ‚Üê async
        # ...
        response = await self.client.embeddings.create(  # ‚Üê await
            model=self.model,
            input=valid_texts,
        )
        # ...
```

---

**T064: Refatorar RetrievalService para async**

**Arquivo**: `src/services/retrieval_service.py`

**Mudan√ßas**:
```python
from qdrant_client import AsyncQdrantClient  # ‚Üê Mudar para Async

class RetrievalService:
    def __init__(self, db: Session | None = None):
        self.qdrant_client = AsyncQdrantClient(  # ‚Üê Async
            url=settings.qdrant_url,
            api_key=settings.qdrant_api_key,
        )

    async def retrieve(  # ‚Üê async def
        self,
        query_vector: List[float],
        collection: str,
        top_k: int,
        min_score: float,
    ) -> List[RetrievalResult]:
        # ...
        search_results = await self._search_qdrant(...)  # ‚Üê await
        retrieval_results = await self._enrich_with_chunk_data(...)  # ‚Üê await
        # ...

    async def _search_qdrant(...) -> List[ScoredPoint]:  # ‚Üê async
        results = await self.qdrant_client.query_points(  # ‚Üê await
            collection_name=collection,
            query=query_vector,
            limit=top_k,
        )
        # ...
```

**Nota**: Para acesso ao PostgreSQL, usar `asyncpg` ou executar queries em thread pool:
```python
import asyncio
from functools import partial

# Op√ß√£o 1: Executar em thread pool (mais simples)
loop = asyncio.get_event_loop()
chunk = await loop.run_in_executor(None, partial(doc_repo.get_chunk, UUID(chunk_id)))

# Op√ß√£o 2: Migrar para SQLAlchemy async (mais complexo)
```

---

**T065: Refatorar GenerationService para async**

**Arquivo**: `src/services/generation_service.py`

**Mudan√ßas**:
```python
from openai import AsyncOpenAI  # ‚Üê Async

class GenerationService:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.openai_api_key)  # ‚Üê Async

    async def generate_answer(  # ‚Üê async def
        self,
        question: str,
        retrieval_results: List[RetrievalResult],
        temperature: float | None = None,
    ) -> GenerationResult:
        # ...
        response = await self.client.chat.completions.create(  # ‚Üê await
            model=self.model,
            messages=[...],
            temperature=temperature or self.temperature,
            max_tokens=self.max_tokens,
        )
        # ...
```

---

**T066: Refatorar GuardrailsService para async**

**Arquivo**: `src/services/guardrails_service.py`

**Mudan√ßas**:
```python
class GuardrailsService:
    async def validate_query(self, query: str) -> ValidationResult:  # ‚Üê async
        # Valida√ß√µes s√£o s√≠ncronas (regex, etc), mas manter async para consist√™ncia
        # Pode rodar em thread pool se necess√°rio
        return ValidationResult(...)
```

---

### Phase 3: Refatorar Workers para Async (2-3h)

**T067: Refatorar BaseWorker para async com aio-pika**

**Arquivo**: `src/workers/base_worker.py`

**Mudan√ßas**:
```python
import asyncio
from aio_pika import connect_robust, Message, IncomingMessage
from aio_pika.abc import AbstractChannel, AbstractConnection

class BaseWorker(ABC):
    def __init__(self, queue_name: str, prefetch_count: int = 10):
        self.queue_name = queue_name
        self.prefetch_count = prefetch_count
        self.connection: AbstractConnection | None = None
        self.channel: AbstractChannel | None = None

    async def _connect(self) -> None:
        self.connection = await connect_robust(settings.rabbitmq_url)
        self.channel = await self.connection.channel()
        await self.channel.set_qos(prefetch_count=self.prefetch_count)

    async def _on_message(self, message: IncomingMessage) -> None:
        async with message.process():
            body = message.body.decode()
            data = json.loads(body)

            # Process message (implementado por subclasse)
            await self.process_message(data)

    @abstractmethod
    async def process_message(self, message: Dict[str, Any]) -> Any:
        """Subclasses must implement this as async"""
        pass

    async def start(self) -> None:
        await self._connect()
        queue = await self.channel.declare_queue(self.queue_name, durable=True)
        await queue.consume(self._on_message)

        # Keep running
        try:
            await asyncio.Future()  # Run forever
        finally:
            await self._disconnect()
```

---

**T068: Refatorar QueryWorker para async**

**Arquivo**: `src/workers/query_worker.py`

**Mudan√ßas**:
```python
class QueryWorker(BaseWorker):
    async def process_message(self, message: Dict[str, Any]) -> Any:  # ‚Üê async
        query_id = message.get("query_id")
        question = message.get("query_text")
        # ...

        # Todas as chamadas agora s√£o await
        validation_result = await self.guardrails_service.validate_query(question)

        query_embedding = await self.embedding_service.generate_embedding(
            sanitized_question
        )

        retrieval_results = await self.retrieval_service.retrieve(
            query_vector=query_embedding,
            collection=collection,
            top_k=max_chunks,
        )

        generation_result = await self.generation_service.generate_answer(
            question=sanitized_question,
            retrieval_results=retrieval_results,
        )

        # Database operations podem usar thread pool ou async SQLAlchemy
        # ...

async def main():
    worker = QueryWorker()
    await worker.start()

if __name__ == "__main__":
    asyncio.run(main())
```

---

### Phase 4: Atualizar API Endpoints (1h)

**T069: Garantir que endpoints da API usem await nos services**

**Arquivo**: `src/api/routes/query.py`

**Mudan√ßas**:
Os endpoints j√° s√£o `async def`, mas precisam usar `await` ao chamar services:

```python
@router.post("/query/async")
async def create_query_async(
    request: QueryRequest,
    db: Session = Depends(get_db),
) -> AsyncQueryResponse:
    # J√° est√° async, apenas garantir que usa await se necess√°rio
    # A publica√ß√£o no RabbitMQ tamb√©m pode ser async com aio-pika
    pass
```

---

### Phase 5: Atualizar Database Layer (2-3h) - OPCIONAL

**T070: Migrar para SQLAlchemy Async (Opcional mas recomendado)**

**Arquivo**: `src/lib/database.py`

**Op√ß√£o 1: Thread Pool (mais simples)**
```python
import asyncio
from functools import partial

# Wrapper para executar queries s√≠ncronas em thread pool
async def run_in_threadpool(func, *args, **kwargs):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, partial(func, *args, **kwargs))
```

**Op√ß√£o 2: SQLAlchemy Async (melhor performance)**
```python
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

engine = create_async_engine(
    settings.database_url.replace("postgresql://", "postgresql+asyncpg://"),
    echo=settings.debug,
)

async def get_db():
    async with AsyncSession(engine) as session:
        yield session
```

---

### Phase 6: Testes e Valida√ß√£o (1-2h)

**T071: Testar pipeline async end-to-end**

1. Iniciar worker async
2. Submeter m√∫ltiplas queries simultaneamente
3. Verificar que queries s√£o processadas em paralelo
4. Medir throughput (queries/segundo)
5. Comparar performance antes/depois

**M√©tricas Esperadas**:
- **Antes**: ~10-20 queries/min (s√≠ncrono, bloqueante)
- **Depois**: ~100-200 queries/min (async, concorrente)
- **Lat√™ncia**: Redu√ß√£o de 30-50% por query individual
- **Concorr√™ncia**: Worker pode processar N queries simultaneamente (N = prefetch_count)

**Scripts de teste**:
```bash
# Testar com 10 queries simult√¢neas
python scripts/test_async_performance.py --queries 10

# Testar throughput
python scripts/benchmark_async.py --duration 60s
```

---

## üîÑ Ordem de Implementa√ß√£o Recomendada

### Dia 1: Funda√ß√£o Async (3-4h)
1. ‚úÖ Criar branch `002-async-refactor`
2. ‚è≥ Atualizar `requirements.txt` com depend√™ncias async (T062)
3. ‚è≥ Refatorar `EmbeddingService` para async (T063)
4. ‚è≥ Refatorar `GenerationService` para async (T065)
5. ‚è≥ Testar services isoladamente

### Dia 2: Services e Workers (3-4h)
6. ‚è≥ Refatorar `RetrievalService` para async (T064)
7. ‚è≥ Refatorar `GuardrailsService` para async (T066)
8. ‚è≥ Refatorar `BaseWorker` com aio-pika (T067)
9. ‚è≥ Refatorar `QueryWorker` para async (T068)
10. ‚è≥ Testar worker com queries reais

### Dia 3: API e Valida√ß√£o (2-3h)
11. ‚è≥ Atualizar API endpoints se necess√°rio (T069)
12. ‚è≥ Implementar database async (thread pool) (T070)
13. ‚è≥ Testes de performance e valida√ß√£o (T071)
14. ‚è≥ Merge para main ap√≥s valida√ß√£o

---

## üìä Checklist de Valida√ß√£o

Antes de fazer merge da branch:

### Funcionalidade
- [ ] Worker consegue processar queries
- [ ] Todas as etapas do pipeline funcionam
- [ ] Respostas geradas t√™m mesma qualidade
- [ ] Errors s√£o tratados corretamente
- [ ] Graceful shutdown funciona

### Performance
- [ ] M√∫ltiplas queries processam em paralelo
- [ ] Throughput aumentou significativamente
- [ ] Lat√™ncia individual n√£o piorou
- [ ] Uso de CPU/mem√≥ria √© aceit√°vel
- [ ] Sem memory leaks em teste de longa dura√ß√£o

### Testes
- [ ] Testes unit√°rios dos services passam
- [ ] Testes de integra√ß√£o passam
- [ ] Testes E2E passam
- [ ] Benchmark de performance documentado

---

## üõ†Ô∏è Comandos √öteis

### Desenvolvimento

```bash
# Instalar novas depend√™ncias
pip install -r requirements.txt

# Rodar worker async
python src/workers/query_worker.py

# Testar com curl
curl -X POST http://localhost:8000/api/v1/query/async \
  -H "Content-Type: application/json" \
  -d '{"question": "Teste async?"}'
```

### Debug

```bash
# Ver logs do worker em tempo real
docker-compose logs -f query-worker

# Monitorar RabbitMQ
# Acessar CloudAMQP dashboard

# Profile de performance
python -m cProfile -o profile.stats src/workers/query_worker.py
```

---

## üìö Recursos de Refer√™ncia

**Documenta√ß√£o Oficial**:
- [AsyncOpenAI](https://github.com/openai/openai-python#async-usage)
- [AsyncQdrantClient](https://qdrant.tech/documentation/frameworks/langchain/)
- [aio-pika](https://aio-pika.readthedocs.io/)
- [SQLAlchemy Async](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)
- [asyncio Best Practices](https://docs.python.org/3/library/asyncio-task.html)

**Exemplos**:
- [FastAPI + AsyncOpenAI](https://github.com/tiangolo/fastapi/discussions/8552)
- [Async RAG Pipeline](https://github.com/hwchase17/langchain/discussions/async)

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

### Risco 1: Complexidade do c√≥digo aumenta
**Mitiga√ß√£o**:
- Manter padr√µes claros de async/await
- Documentar bem cada mudan√ßa
- Testes abrangentes

### Risco 2: Bugs dif√≠ceis de debugar
**Mitiga√ß√£o**:
- Logging estruturado detalhado
- Tracing de requests (correlation IDs)
- Testes de concorr√™ncia

### Risco 3: Performance pode n√£o melhorar como esperado
**Mitiga√ß√£o**:
- Benchmarks antes e depois
- Profiling para identificar gargalos
- Rollback plan (manter branch anterior)

---

## üéØ Defini√ß√£o de Sucesso

A refatora√ß√£o ser√° considerada bem-sucedida quando:

1. ‚úÖ **Throughput**: ‚â• 5x melhor (de ~20 para ~100+ queries/min)
2. ‚úÖ **Concorr√™ncia**: Worker processa N queries simultaneamente
3. ‚úÖ **Lat√™ncia**: Individual n√£o aumenta (idealmente reduz 30%)
4. ‚úÖ **Qualidade**: Respostas mant√™m mesma qualidade
5. ‚úÖ **Estabilidade**: Sistema roda por 24h sem crashes
6. ‚úÖ **Testes**: 100% dos testes passando

---

## üìù Progresso Atual

**Branch**: `002-async-refactor`
**Status**: üü° Iniciado
**Completado**: 0/11 tasks (0%)

### Tasks
- [ ] T062: Atualizar requirements.txt
- [ ] T063: Async EmbeddingService
- [ ] T064: Async RetrievalService
- [ ] T065: Async GenerationService
- [ ] T066: Async GuardrailsService
- [ ] T067: Async BaseWorker
- [ ] T068: Async QueryWorker
- [ ] T069: Atualizar API endpoints
- [ ] T070: Database async (opcional)
- [ ] T071: Testes e valida√ß√£o
- [ ] T072: Merge para main

---

**√öltima modifica√ß√£o**: 2025-11-20
**Pr√≥xima a√ß√£o**: Atualizar requirements.txt com depend√™ncias async (T062)
**Meta final**: Sistema RAG completamente ass√≠ncrono com 5x melhor throughput

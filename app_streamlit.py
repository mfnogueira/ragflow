"""
RagFlow - Interface Streamlit para Q&A sobre Reviews da Olist

Aplica√ß√£o web para fazer perguntas sobre reviews de e-commerce
e receber respostas geradas por IA com evid√™ncias de suporte.
"""

import streamlit as st
import requests
import time
from datetime import datetime
from typing import Dict, List, Optional

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="RagFlow - Q&A sobre Reviews Olist",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√µes da API
API_BASE_URL = st.sidebar.text_input(
    "URL da API",
    value="http://localhost:8000",
    help="URL base da API FastAPI"
)

# Estilo customizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .query-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .answer-box {
        background-color: #e8f4f8;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border-left: 4px solid #1f77b4;
    }
    .confidence-high {
        color: #28a745;
        font-weight: bold;
    }
    .confidence-medium {
        color: #ffc107;
        font-weight: bold;
    }
    .confidence-low {
        color: #dc3545;
        font-weight: bold;
    }
    .source-box {
        background-color: #fff3cd;
        padding: 0.8rem;
        border-radius: 0.3rem;
        margin: 0.5rem 0;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.markdown('<div class="main-header">ü§ñ RagFlow - Q&A sobre Reviews Olist</div>', unsafe_allow_html=True)
st.markdown("Fa√ßa perguntas sobre reviews de e-commerce e receba respostas geradas por IA")
st.info("‚ÑπÔ∏è **MODO DEMONSTRA√á√ÉO**: Usando respostas simuladas para testar a interface (RabbitMQ, OpenAI e Qdrant n√£o est√£o ativos)")

# Inicializar session state
if 'query_history' not in st.session_state:
    st.session_state.query_history = []
if 'current_query_id' not in st.session_state:
    st.session_state.current_query_id = None


def check_api_health() -> bool:
    """Verifica se a API est√° dispon√≠vel."""
    try:
        response = requests.get(f"{API_BASE_URL}/health/", timeout=5)
        return response.status_code == 200
    except Exception:
        return False


def submit_query_async(question: str, collection: str = "olist_reviews") -> Optional[Dict]:
    """Submete uma query (MODO DEMO - respostas simuladas localmente)."""
    # MODO DEMO: Simula respostas localmente sem chamar API
    from uuid import uuid4

    query_id = str(uuid4())

    # Retorna query_id simulado
    return {
        "query_id": query_id,
        "message": "Query processada (DEMO MODE)"
    }


def get_query_status(query_id: str) -> Optional[Dict]:
    """Obt√©m o status e resultado de uma query (MODO DEMO)."""
    from datetime import datetime

    # MODO DEMO: Retorna dados simulados sem chamar API
    # Simula um pequeno delay para realism
    import time
    time.sleep(0.5)

    # Pega a pergunta do session state se dispon√≠vel
    question = st.session_state.get('current_question', 'Pergunta sobre reviews')

    #  Respostas simuladas baseadas em palavras-chave
    demo_answers = {
        "negativ": "Com base nos reviews analisados, os principais motivos de avalia√ß√µes negativas s√£o: **(1) Atrasos na entrega** - muitos clientes reclamam de produtos que chegaram com semanas de atraso; **(2) Produtos diferentes do anunciado** - discrep√¢ncias entre descri√ß√£o e produto recebido; **(3) Problemas com qualidade** - produtos com defeitos ou danificados no transporte.",
        "elogiam": "Os clientes mais elogiam: **(1) Qualidade dos produtos** - muitos coment√°rios sobre produtos que superaram expectativas; **(2) Atendimento** - vendedores atenciosos e prestativos; **(3) Embalagem** - cuidado no empacotamento e apresenta√ß√£o; **(4) Pre√ßos competitivos** - bom custo-benef√≠cio.",
        "categoria": "As categorias com melhores avalia√ß√µes s√£o: **(1) Livros e m√≠dia** - score m√©dio de 4.5/5; **(2) Produtos de beleza e cuidados pessoais** - 4.3/5; **(3) Inform√°tica e eletr√¥nicos** - 4.2/5. As categorias com avalia√ß√µes mais baixas incluem m√≥veis (3.8/5) e produtos para casa (3.9/5).",
        "entrega": "As principais reclama√ß√µes sobre entrega incluem: **(1) Prazos n√£o cumpridos** - 45% das reclama√ß√µes; **(2) Falta de rastreamento** - 25%; **(3) Produtos perdidos ou extraviados** - 15%; **(4) Problemas com transportadora** - 10%; **(5) Outros** - 5%.",
        "qualidade": "Sobre a qualidade dos produtos, os clientes mencionam: **(1) Maioria dos produtos atende ou supera expectativas** (65% positivo); **(2) Alguns produtos com qualidade inferior ao esperado** (20% negativo); **(3) Problemas com descri√ß√µes imprecisas** (15%). Produtos de marcas reconhecidas t√™m melhor avalia√ß√£o de qualidade."
    }

    # Encontrar melhor resposta
    question_lower = question.lower()
    answer_text = "Com base nos reviews analisados, podemos fornecer informa√ß√µes sobre diversos aspectos das avalia√ß√µes de clientes. Os dados indicam padr√µes interessantes de satisfa√ß√£o e reclama√ß√µes que podem ajudar a entender melhor a experi√™ncia dos consumidores."
    confidence = 0.75

    for keyword, text in demo_answers.items():
        if keyword in question_lower:
            answer_text = text
            confidence = 0.85
            break

    # Retorna resultado simulado
    return {
        "query_id": query_id,
        "question": question,
        "status": "completed",
        "answer": answer_text,
        "confidence_score": confidence,
        "sources": [
            {"chunk_id": f"demo-chunk-{i+1}", "similarity_score": 0.85 - (i * 0.05)}
            for i in range(3)
        ],
        "created_at": datetime.now().isoformat(),
        "completed_at": datetime.now().isoformat()
    }


def wait_for_answer(query_id: str, max_wait: int = 60, poll_interval: int = 2) -> Optional[Dict]:
    """Aguarda a resposta da query com polling."""
    start_time = time.time()
    progress_bar = st.progress(0, text="Processando sua pergunta...")
    status_text = st.empty()

    while time.time() - start_time < max_wait:
        result = get_query_status(query_id)

        if result:
            status = result.get('status')

            if status == 'completed':
                progress_bar.progress(100, text="‚úÖ Resposta pronta!")
                time.sleep(0.5)
                progress_bar.empty()
                status_text.empty()
                return result
            elif status == 'failed':
                progress_bar.empty()
                status_text.empty()
                st.error("‚ùå Falha ao processar a query")
                return None
            else:
                # Atualizar progresso
                elapsed = int(time.time() - start_time)
                progress = min(int((elapsed / max_wait) * 100), 90)
                progress_bar.progress(progress, text=f"üîÑ Processando... ({elapsed}s)")
                status_text.info(f"Status: {status}")

        time.sleep(poll_interval)

    progress_bar.empty()
    status_text.empty()
    st.warning("‚è±Ô∏è Timeout: A query est√° demorando mais do que o esperado. Tente novamente mais tarde.")
    return None


def get_confidence_class(confidence: float) -> str:
    """Retorna a classe CSS baseada no score de confian√ßa."""
    if confidence >= 0.8:
        return "confidence-high"
    elif confidence >= 0.6:
        return "confidence-medium"
    else:
        return "confidence-low"


def get_confidence_emoji(confidence: float) -> str:
    """Retorna emoji baseado no score de confian√ßa."""
    if confidence >= 0.8:
        return "‚úÖ"
    elif confidence >= 0.6:
        return "‚ö†Ô∏è"
    else:
        return "‚ùå"


def display_answer(result: Dict):
    """Exibe a resposta de forma formatada."""
    st.markdown('<div class="answer-box">', unsafe_allow_html=True)

    # Pergunta
    st.markdown(f"**‚ùì Pergunta:** {result['question']}")
    st.markdown("---")

    # Resposta
    if result.get('answer'):
        st.markdown(f"**üí° Resposta:**")
        st.markdown(result['answer'])

        # Score de confian√ßa
        if result.get('confidence_score') is not None:
            confidence = result['confidence_score']
            confidence_class = get_confidence_class(confidence)
            confidence_emoji = get_confidence_emoji(confidence)

            st.markdown(f"""
            **{confidence_emoji} Confian√ßa:**
            <span class="{confidence_class}">{confidence:.1%}</span>
            """, unsafe_allow_html=True)

            # Barra de progresso visual
            st.progress(confidence)

        # Fontes/Chunks
        if result.get('sources'):
            st.markdown("---")
            st.markdown(f"**üìö Fontes ({len(result['sources'])} chunks):**")

            for idx, source in enumerate(result['sources'][:3], 1):
                similarity = source.get('similarity_score', 0)
                st.markdown(
                    f'<div class="source-box">'
                    f'üìÑ Fonte {idx} - Similaridade: {similarity:.1%}<br>'
                    f'<small>Chunk ID: {source.get("chunk_id", "N/A")[:8]}...</small>'
                    f'</div>',
                    unsafe_allow_html=True
                )
    else:
        st.warning("‚è≥ Resposta ainda n√£o est√° dispon√≠vel")

    # Metadados
    with st.expander("‚ÑπÔ∏è Informa√ß√µes da Query"):
        st.json({
            "Query ID": result.get('query_id'),
            "Status": result.get('status'),
            "Criado em": result.get('created_at'),
            "Completado em": result.get('completed_at')
        })

    st.markdown('</div>', unsafe_allow_html=True)


def display_statistics():
    """Exibe estat√≠sticas do sistema."""
    try:
        response = requests.get(f"{API_BASE_URL}/health/metrics", timeout=5)
        if response.status_code == 200:
            metrics = response.json()

            col1, col2, col3, col4 = st.columns(4)

            db_metrics = metrics.get('database', {})

            with col1:
                st.metric(
                    "üìÑ Documentos",
                    db_metrics.get('total_documents', 0)
                )

            with col2:
                st.metric(
                    "üìù Chunks",
                    db_metrics.get('total_chunks', 0)
                )

            with col3:
                st.metric(
                    "‚ùì Queries Total",
                    db_metrics.get('total_queries', 0)
                )

            with col4:
                st.metric(
                    "üìö Cole√ß√µes",
                    db_metrics.get('total_collections', 0)
                )
    except Exception:
        pass


# Sidebar - Informa√ß√µes e configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")

    # Status da API
    api_status = check_api_health()
    if api_status:
        st.success("‚úÖ API Online")
    else:
        st.error("‚ùå API Offline")
        st.info(f"Certifique-se que a API est√° rodando em {API_BASE_URL}")

    st.markdown("---")

    # Cole√ß√£o
    collection = st.selectbox(
        "Cole√ß√£o",
        ["olist_reviews"],
        help="Selecione a cole√ß√£o de documentos"
    )

    # Configura√ß√µes avan√ßadas
    with st.expander("üîß Configura√ß√µes Avan√ßadas"):
        max_chunks = st.slider(
            "M√°ximo de chunks",
            min_value=1,
            max_value=10,
            value=5,
            help="N√∫mero m√°ximo de chunks a recuperar"
        )

        confidence_threshold = st.slider(
            "Limiar de confian√ßa",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            step=0.05,
            help="Limiar m√≠nimo de confian√ßa"
        )

        max_wait_time = st.slider(
            "Tempo m√°ximo de espera (s)",
            min_value=10,
            max_value=120,
            value=60,
            step=10,
            help="Tempo m√°ximo para aguardar resposta"
        )

    st.markdown("---")
    st.markdown("### üìä Estat√≠sticas")
    if api_status:
        display_statistics()

    st.markdown("---")
    st.markdown("### ‚ÑπÔ∏è Sobre")
    st.markdown("""
    **RagFlow** √© um sistema RAG que permite fazer perguntas sobre reviews
    de e-commerce e receber respostas geradas por IA.

    üîó [GitHub](https://github.com/mfnogueira/ragflow.git)
    """)


# Interface principal
st.markdown("### üí¨ Fa√ßa sua pergunta")

# Exemplos de perguntas
with st.expander("üí° Exemplos de perguntas"):
    example_queries = [
        "Quais s√£o os principais motivos de avalia√ß√µes negativas?",
        "O que os clientes mais elogiam nos produtos?",
        "Quais categorias de produtos t√™m melhores avalia√ß√µes?",
        "Quais s√£o as principais reclama√ß√µes sobre entrega?",
        "O que os clientes falam sobre a qualidade dos produtos?"
    ]

    for query in example_queries:
        if st.button(f"üìå {query}", key=f"example_{hash(query)}", use_container_width=True):
            st.session_state.question_input = query

# Campo de entrada
question = st.text_area(
    "Digite sua pergunta:",
    height=100,
    placeholder="Ex: Quais s√£o os principais problemas relatados pelos clientes?",
    value=st.session_state.get('question_input', ''),
    key="question_area"
)

# Bot√£o de envio
col1, col2 = st.columns([1, 4])
with col1:
    submit_button = st.button("üöÄ Enviar Pergunta", type="primary", disabled=not api_status)

if submit_button and question.strip():
    # Limpar input
    if 'question_input' in st.session_state:
        del st.session_state.question_input

    st.markdown("---")

    # Salvar pergunta no session state para uso no modo demo
    st.session_state.current_question = question

    # Submeter query
    with st.spinner("Enviando pergunta..."):
        response = submit_query_async(question, collection)

    if response:
        query_id = response.get('query_id')
        st.info(f"‚úÖ Query submetida! ID: `{query_id}`")

        # Aguardar resposta
        result = wait_for_answer(query_id, max_wait=max_wait_time)

        if result:
            # Exibir resposta
            display_answer(result)

            # Adicionar ao hist√≥rico
            st.session_state.query_history.insert(0, {
                'timestamp': datetime.now(),
                'question': question,
                'result': result
            })

# Hist√≥rico
if st.session_state.query_history:
    st.markdown("---")
    st.markdown("### üìú Hist√≥rico de Perguntas")

    for idx, item in enumerate(st.session_state.query_history[:5]):
        with st.expander(f"üïê {item['timestamp'].strftime('%H:%M:%S')} - {item['question'][:60]}..."):
            display_answer(item['result'])

    if len(st.session_state.query_history) > 5:
        st.info(f"Mostrando 5 de {len(st.session_state.query_history)} perguntas")

    # Bot√£o para limpar hist√≥rico
    if st.button("üóëÔ∏è Limpar Hist√≥rico"):
        st.session_state.query_history = []
        st.rerun()

# Footer
st.markdown("---")
st.markdown(
    """
    <div style="text-align: center; color: #888; font-size: 0.9rem;">
        Desenvolvido com ‚ù§Ô∏è usando Python, FastAPI, OpenAI e Streamlit<br>
        <a href="https://github.com/mfnogueira/ragflow.git" target="_blank">‚≠ê D√™ uma estrela no GitHub!</a>
    </div>
    """,
    unsafe_allow_html=True
)
